---
title: "Measuring Covid Measures"
author: "Tisja Smits"
date: "2021"
output: 
    flexdashboard::flex_dashboard:
      orientation: rows
      storyboard: true
      theme: journal # default / cosmo / bootstrap / cerulean / journal! / flatly! / readable / spacelab / united / lumen / paper / sandstone / simplex! / yeti!
---

<style type="text/css">
  body{
  font-family: "Rubik", Light;
  color: black;
  }
</style>


```{r package and theme setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(spotifyr)
library(compmus)

library(flexdashboard)
library(plotly)
library(gridExtra)

library(tidymodels)
library(ggdendro)
library(heatmaply)

theme_mine <-
  theme_minimal() +
  theme(
    text = element_text(family = "Rubik"),
    legend.title = element_blank(),
    strip.text = element_text(color = "black"),
    strip.background = element_rect(fill = "gray90", color = NA),
    panel.border = element_rect(fill = NA, color = "gray80"),
    axis.ticks = element_line(color = "gray80")
    )
```

```{r toptracks setup, include=FALSE}
my2019 <- get_playlist_audio_features("", "37i9dQZF1Etf5utVpuKPi7")  %>% 
  mutate(playlist = "2019", category = "personal")
my2020 <- get_playlist_audio_features("", "37i9dQZF1ELZX0wn2u2RJw") %>% 
  mutate(playlist = "2020", category = "personal")
my2021 <- bind_rows(
  get_playlist_audio_features("", "6US6AXRPEDXScdalyqL3z4"),
  get_playlist_audio_features("", "3o3ct2BSsEfiO2jV7qycsl")
  ) %>% mutate(playlist = "2021", category = "personal")

pop <- get_playlist_audio_features("", "37i9dQZF1DX6gRTxU4AfAv") %>% 
  mutate(playlist = "Pop", category = "genres")
dance <- get_playlist_audio_features("", "37i9dQZF1DX0W5G2DBOR2F") %>% 
  mutate(playlist = "Dance", category = "genres")
hiphop <- get_playlist_audio_features("", "37i9dQZF1DX6rJpshxuzGT")[1:50,] %>% 
  mutate(playlist = "Hip-Hop/R&B", category = "genres")
indie <- get_playlist_audio_features("", "37i9dQZF1DWYeyJxik6dE1") %>% 
  mutate(playlist = "Indie/Rock", category = "genres")

corpus <-
  bind_rows(my2019, my2020, my2021, pop, dance, hiphop, indie)

corpus_stats <- corpus %>% 
  group_by(playlist) %>%
  summarise(
    category = "stat",
    valence_sd = sd(valence),
    valence = mean(valence),
    energy_sd = sd(energy),
    energy = mean(energy),
    tempo_sd = sd(tempo),
    tempo = mean(tempo),
    danceability_sd = sd(danceability),
    danceability = mean(danceability),
    loudness_sd = sd(loudness),
    loudness = mean(loudness),
    track.name = NA,     # or "average"
    time_signature = median(time_signature),
    key = median(key),
    mode_sd = sd(mode),
    mode = mean(mode),
    mode_name = NA
    )
```

Prologue
==================

Row
-------------------------------------

### <font size="3"> Just an average girl? </font>

My initial corpus consisted of my Top Tracks of 2019 and 2020 and the Top Tracks NL of 2019 and 2020. I wanted to analyze how 'average' my taste in music was, and how it changed during the COVID-19 pandemic. Due to the **social distancing measures** I did not listen to music in any social setting, such as hanging out with friends, clubbing, or even working out at the gym.

After seven weeks of homework assignments, disappointing results and hence disappointing data visualizations, I decided to change my corpus. The Top Tracks NL playlists were too 'general' to really capture any meaning or essence of 'the average Dutch taste in music'.

My new corpus consists of 510 tracks from 7 playlists in total. I still use my Top Tracks of 2019 and 2020, but I have added my own 2021 playlist. This way, 2019 represents the pre-pandemic situation and 2021 represent the one-year mark. The other four playlists are playlists of the NL top tracks of 2020, but one for each of the following genres: pop, dance, hip-hop/R&B and indie/rock. These genre playlists are shown below.

### <font size="3"> A clean slate </font>

I want to analyze the following about this new corpus:

**1. In terms of genre, how can my taste in music best be described?**

**2. How has my taste in music evolved during the COVID-19 pandemic?**

It is important to note that the playlists do not contain the same amount of tracks. The four genre playlists each contain 50 tracks. My 2019 and 2020 playlists contain 100 tracks and my 2021 playlist contains 110 tracks. I deciced not to take out the extra 10, because there was no satisfactory objective way of doing so.

It is also important to note that my 2021 playlist is the *only* playlist I have compiled myself, the others were compiled by Spotify. It might be the case that Spotify biases the playlists by including certain --possibly sponsored-- songs. Although I do not consider this plausible, it is important to keep in mind.

More plausible is the possibility of my personal Top Tracks playlists being biased, for different reasons however. First, I do not have a premium Spotify account, which means I get a limited amount of skips per hour and most playlists can only be played on shuffle. It might be that a song ended up a Top Track because it was in a playlist I listened to a lot, not because I liked that song so much. This limitation, however, only applies when listening to Spotify on my phone. The desktop version of Spotify *does* allow for infinite skips and the freedom to choose songs manually, put songs in the waiting list, and play a playlist on shuffle or in order. 

A great example of a dubious song is **"Stuck with U" by Ariana Grande and Justin Bieber**. It is one of my Top Tracks of 2020. It used to be in a lot of different playlists I listened to at the time. And yes, I liked that song, but nevertheless, I am fairly sure there were other songs I liked more in 2020. I definitely consider this song atypical for my taste in music in 2020.

<iframe src="https://open.spotify.com/embed/track/4HBZA5flZLE435QTztThqH" width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

Contrarily, a song I consider very typical for my taste is **"Drive and Disconnect" by Nao**. I remember listening to this song on repeat when I discovered it early 2019, but also for a longer time after that. And even a few months later I rediscovered this song, and fell in love all over again. Even now, it is still one of my favorite songs.

<iframe src="https://open.spotify.com/embed/track/6pEAd0UjznaKABT7WLLvmC" width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

Row
-------------------------------------

### <font size="3"> Genre playlists </font>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX6gRTxU4AfAv" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX6rJpshxuzGT" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX0W5G2DBOR2F" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DWYeyJxik6dE1" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>


A good first impression {.storyboard}
==================

### <font size="3"> An emotional analysis of the lockdown: (no) time to relax </font> {data-commentary-width=450}

```{r mood plot, fig.align="center", out.height="90%"}
ggplotly(ggplot(
    corpus,
    aes(x = valence,
        y = energy,
        color = valence + energy,
        label = track.name)) +
  geom_point(alpha = 0.5) +
  scale_color_viridis(guide = "none", option = "inferno") +

  geom_segment(
    data = corpus_stats, 
    aes(x = valence, 
        y = energy-energy_sd, 
        xend = valence, 
        yend = energy+energy_sd)) +
  geom_segment(
    data = corpus_stats, 
    aes(x = valence-valence_sd, 
        y = energy, 
        xend = valence+valence_sd, 
        yend = energy)) +
  geom_point(
    data = corpus_stats,
    size = 2.5) +

  scale_x_continuous(breaks=seq(0,1,0.25)) +
  scale_y_continuous(breaks=seq(0,1,0.25)) +
  facet_wrap(~playlist) +
  labs(x = "Valence",
       y = "\nEnergy\n") +
  theme_mine,
  )
```

***
<font size="4"> Scatter plot of energy versus valence with mean and SD per playlist </font>

*The means are represented by the bigger dots, the SDs by the line segments.*

Overall, I am really not surprised by the results of this energy-valence scatter plot. It is pretty much what I expected  about these features. At frist, I was surprised that my playlists are so diverse. Later, I realized that I indeed listen to all kinds of emotion in music.

My personal playlists seem to resemble each other the most. Their means, as well as their scattering, are most similar to the pop genre The shape of the 2021 scattering, however, seems to have slightly shifted toward hip-hop/R&B. I already suspected it would, because I have been discovering some nice new R&B artists lately.

The genres dance and indie/rock look least like my playlist, which also makes sense, since I don't listen to that much. It is very interesting to see that indie/rock is so all over the place. I am not a real indie-expert, so I would not know if this was to be expected. I *did* expect rock to have some tracks in the upper-left corner, which it does indeed. What is so interesting about dance, is that the tracks lie very close to each other in the spectrum. With electronic instrumentation, it makes sense that the energy of dance tracks is overall high.


### <font size="3"> [**knaldrang**](https://www.urbandictionary.com/define.php?term=knaldrang) [knal-drang] *noun* -- The intense desire to go out, to party, to dance. </font> {data-commentary-width=450}

```{r dance plot, fig.align="center", out.width="80%"}
ggplotly(ggplot(
    corpus,
    aes(x = tempo,
        y = danceability,
        color = (tempo * danceability)^0.7,
        label = track.name)) +
  geom_point(alpha = 0.5) +
  scale_color_viridis(guide = "none", option = "inferno") +

  geom_segment(
    data = corpus_stats, 
    aes(x = tempo, 
        y = danceability-danceability_sd, 
        xend = tempo, 
        yend = danceability+danceability_sd)) +
  geom_segment(
    data = corpus_stats, 
    aes(x = tempo-tempo_sd, 
        y = danceability, 
        xend = tempo+tempo_sd, 
        yend = danceability)) +
  geom_point(
    data = corpus_stats,
    size = 2.5) +

  scale_x_continuous(breaks=seq(20,220,40)) +
  # scale_y_continuous(breaks=seq(0,1,0.25)) +
  facet_wrap(~playlist) +
  labs(x = "Tempo (bpm)",
       y = "Danceability") +
  theme_mine
)
```

***
<font size="4"> Scatter plot of danceability versus tempo with mean and SD per playlist </font>
*The means are represented by the bigger dots, the SDs by the line segments.*

What strikes me the most, is that the tracks in my personal playlists all cluster around 100 bpm. When I saw this visualization, I immediately wanted to check it. And indeed, at 100 bpm, my body seems to start moving to the music effortlessly. So unlike what [Moelants (2002)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.8019&rep=rep1&type=pdf) showed, my preferred tempo *does* lie at 100 bpm.

Just like my playlists, the genres hip-hop/R&B and pop also seem to have a cluster of tracks around 100 bpm, although less obvious. Notice that all of their means are slightly higher, since they spread out more to the right. Indie/rock is clustered more around 120 bpm, and dance even more so.

The average danceabilities of my playlists lie between 0.6 and 0.9. The means, of about 0.7 confirm this. Dance tracks are spread out from about 0.5 to 0.9, also with a mean of 0.7. Not surprisingly, pop and indie/rock tracks have a somewhat lower danceability. Hip-hop/R&B tracks, however, have a slightly higher danceability.

In conclusion, regarding tempo and danceability, my taste in music can be characterized by the genres pop and hip-hop/R&B. Also, I have gotten very curious what exactly determines danceability for the Spotify API, since it does not *necessarily* take tempo into account.


### <font size="3"> It's in the minor details of this major pandemic </font> {data-commentary-width=450}

```{r mode barplot, fig.align="center", out.width="60%"}
ggplotly(ggplot(
  corpus,
  aes(x = playlist,
      fill = mode_name)) +
  geom_bar(position = "fill", alpha = 0.75) +

  scale_x_discrete(limits = c("2019","2020","2021","","Hip-Hop/R&B","Dance","Indie/Rock","Pop")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL, y = NULL, title = "Distribution of modes across playlists") +
  theme_mine +
  theme(panel.grid.major.x = element_blank()),
)
```

***
It is immediately apparent that the indie/rock and pop playlists contain relatively more major than minor tracks, as opposed to the other playlists. Also, my 2021 tracks are more likely to be in minor mode than my Top Tracks of 2019 or 2020. As in the energy-valence visualization, this might indicate that my taste in music has slightly shifted towards R&B. As opposed to previous results, this barplot shows that, regarding mode, my taste in music can be *least* characterized by pop.  



Getting on track {.storyboard}
==================

```{r gram setup}
sweetie <-
  get_tidy_audio_analysis("2UAl2nzSixQviGw0XJvJgY") %>%  # Change URI.
  compmus_align(bars, segments) %>%                      # Change `bars`
  select(bars) %>%                                       #   in all three
  unnest(bars) %>%                                       #   of these lines.
  mutate(pitches = map(
    segments, compmus_summarise, pitches,
    method = "mean", norm = "euclidean"              # Change summary & norm.
      )) %>%
  mutate(timbre = map(
    segments, compmus_summarise, timbre,
    method = "rms", norm = "euclidean"               # Change summary & norm.
    ))
sweetie_sec <-
  get_tidy_audio_analysis("2UAl2nzSixQviGw0XJvJgY") %>%  # Change URI.
  compmus_align(sections, segments) %>%                      # Change `bars`
  select(sections) %>%                                       #   in all three
  unnest(sections) %>%                                       #   of these lines.
  mutate(pitches = map(
    segments, compmus_summarise, pitches,
    method = "mean", norm = "euclidean"              # Change summary & norm.
    )) %>%
  mutate(timbre = map(
    segments, compmus_summarise, timbre,
    method = "rms", norm = "euclidean"               # Change summary & norm.
    ))

arrow1 <- arrow(length = unit(0.1, "cm"), ends = "both", type = "closed")
```

### <font size="3"> A chroma analysis: repetitive chord progressions and clear verse-chorus structures by melody and harmony </font> {data-commentary-width=450}

```{r chromagrams bars and sections}
bind_rows(
  sweetie %>% 
    compmus_gather_chroma() %>% mutate(type = "Bars"),
  sweetie_sec %>% 
    compmus_gather_chroma() %>% mutate(type = "Sections")
  ) %>%
  mutate() %>% ggplot(
    aes(x = start + duration / 2,
        width = duration,
        y = pitch_class,
        fill = value)) +
  geom_tile() +
  
  annotate("text", x = 14, y = 9.1, label = "guitar", color = "white") +
  annotate("segment", x = 0, xend = 8, y = 8.5, yend = 8.5, color = "white", arrow=arrow1) +
  annotate("text", x = 25, y = 7, label = "percussion", color = "white") +
  annotate("segment", x = 9, xend = 20, y = 6.5, yend = 6.5, color = "white", arrow=arrow1) +
  annotate("text", x = 50, y = 4, label = "chorus", color = "white") +
  annotate("segment", x = 39, xend = 58, y = 3.5, yend = 3.5, color = "white", arrow=arrow1) +
  annotate("text", x = 110, y = 2, label = "bridge", color = "white") +
  annotate("segment", x = 102, xend = 115, y = 1.5, yend = 1.5, color = "white", arrow=arrow1) +
  annotate("text", x = 126, y = 4, label = "chorus", color = "white") +
  annotate("segment", x = 116, xend = 136, y = 3.5, yend = 3.5, color = "white", arrow=arrow1) +
  
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_fill_viridis_c("Magnitude", option = "inferno") +
  facet_wrap(~type) +
  labs(x = "Time (s)", y = NULL, 
       title = "Chromagrams", 
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(legend.title = element_text(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

This song was one of my favorite tracks of 2020 and a pretty typical as well (see song info). In the bars chromagram, you can clearly see the repetitive chord progression throughout the song -- e.g. the skips from C to G. The sections chromagram clearly shows bright 'blocks' at D and C. The D-blocks represent the chorus vocals and the C-block represents the vocals in the bridge. The first few blocks at G and F represent the instrumental intro.

I think the overall look of these chromagrams are very representative of the tracks I generally listen to. Speaking from a music theoretic point of view, most songs have a clear verse-chorus structure (as shown by the the sections chromagram) and simple melodies and harmonies (as shown by the bars chromagram). However, the verse-chorus structure of this song is much *different* than the usual "verse-chorus-verse-chorus-bridge-chorus" from pop songs (see song structure).

#### Song info
Feature        | Average in 2020                         | "Sweetie Odo" 
---------------|-----------------------------------------|--------------
Key            | F# major                                | G minor
Time Signature | `r median(my2020$time_signature)`       | 4
BPM            | `r round(mean(my2020$tempo), 2)`        | 100
Energy         | `r round(mean(my2020$energy), 2)`       | 0.49
Valence        | `r round(mean(my2020$valence), 2)`      | 0.53
Danceability   | `r round(mean(my2020$danceability), 2)` | 0.84

#### Song structure
Time (s) | Section             | Instrumentation
-------- | ------------------- | ----------
0-9      | intro               | guitar
10-19    | intro               | + percussion
19-38    | intro               | + voice
38-57    | chorus              |
57-76    | post-chorus         |
76-96    | verse               |
96-114   | bridge              |
114-134  | chorus              |
134-155  | outro / post-chorus | - guitar


### <font size="3"> A timbre analysis: clear verse-chorus structures by instrumentation </font> {data-commentary-width=450}
```{r cepstrograms bars and sections}
bind_rows(
  sweetie %>% 
    compmus_gather_timbre() %>% mutate(type = "Bars"),
  sweetie_sec %>% 
    compmus_gather_timbre() %>% mutate(type = "Sections")
) %>%
  mutate() %>% ggplot(
    aes(x = start + duration / 2,
        width = duration,
        y = basis,
        fill = value)) +
  geom_tile() +
  
  annotate("text", x = 20, y = 4, label = "intro", color = "white") +
  annotate("segment", x = 0, xend = 38, y = 3.5, yend = 3.5, color = "white", arrow=arrow1) +
  annotate("text", x = 69, y = 6, label = "post-chorus", color = "white") +
  annotate("segment", x = 59, xend = 78, y = 5.5, yend = 5.5, color = "white", arrow=arrow1) +
  annotate("text", x = 90, y = 4, label = "verse", color = "white") +
  annotate("segment", x = 78, xend = 100, y = 3.5, yend = 3.5, color = "white", arrow=arrow1) +
  annotate("text", x = 110, y = 1.1, label = "bridge", color = "white") +
  annotate("segment", x = 102, xend = 115, y = 1.5, yend = 1.5, color = "white", arrow=arrow1) +
  annotate("text", x = 126, y = 6, label = "chorus", color = "white") +
  annotate("segment", x = 116, xend = 136, y = 5.5, yend = 5.5, color = "white", arrow=arrow1) +
  annotate("text", x = 144, y = 4, label = "outro", color = "white") +
  annotate("segment", x = 137, xend = 156, y = 3.5, yend = 3.5, color = "white", arrow=arrow1) +
  
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_fill_viridis_c("Magnitude", option = "inferno") +
  facet_wrap(~type) +
  labs(x = "Time (s)", y = NULL,
       title = "Cepstrograms",
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(legend.title = element_text(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

This song was one of my favorite tracks of 2020 and a pretty typical as well (see song info). Both cepstrograms clearly show the intro and outro in the third timbre component. The verses is also brighter in c03. The chorus sections, however, light up in c05. I wonder what this component represents. The second timbre component most clearly shows the bridge and the choruses somewhat.

What is most representative about this song, and clearly visualized in these cepstrograms, is that most songs I listen to have an intro and outro. Also, I believe I do not listen to many songs where the loudness -- the first timbre component -- changes a lot.

#### Song info
Feature        | Average in 2020                         | "Sweetie Odo" 
---------------|-----------------------------------------|--------------
Time Signature | `r median(my2020$time_signature)`       | 4
BPM            | `r round(mean(my2020$tempo), 2)`        | 100
Energy         | `r round(mean(my2020$energy), 2)`       | 0.49
Valence        | `r round(mean(my2020$valence), 2)`      | 0.53
Danceability   | `r round(mean(my2020$danceability), 2)` | 0.84

#### Song structure
Time (s) | Section             | Instrumentation
-------- | ------------------- | ----------
0-9      | intro               | guitar
10-19    | intro               | + percussion
19-38    | intro               | + voice
38-57    | chorus              |
57-76    | post-chorus         |
76-96    | verse               |
96-114   | bridge              |
114-134  | chorus              |
134-155  | outro / post-chorus | - guitar


### <font size="3"> The song that just keeps on giving </font> {data-commentary-width=450}
```{r self-similarity matrices}
bind_rows(
  sweetie %>%
    compmus_self_similarity(pitches, "euclidean") %>%
    mutate(d = d / max(d), type = "Chroma"),
  sweetie %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(aes(
    x = xstart + xduration / 2,
    width = xduration,
    y = ystart + yduration / 2,
    height = yduration,
    fill = d)) +
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_y_continuous(breaks=seq(0,155,30)) +
  geom_tile() +
  coord_fixed() +
  
  annotate("text", x = 19, y = 42, label = "intro", color = "white") +
  annotate("segment", x = 2, xend = 38, y = 38, yend = 38, color = "white", arrow=arrow1) +
  annotate("text", x = 48, y = 62, label = "chorus", color = "white") +
  annotate("segment", x = 39, xend = 57, y = 57, yend = 57, color = "white", arrow=arrow1) +
  annotate("text", x = 67, y = 53, label = "post-", color = "white") +
  annotate("segment", x = 57, xend = 76, y = 57, yend = 57, color = "white", arrow=arrow1) +
  annotate("text", x = 86, y = 101, label = "verse", color = "white") +
  annotate("segment", x = 77, xend = 96, y = 96, yend = 96, color = "white", arrow=arrow1) +
  annotate("text", x = 105, y = 120, label = "bridge", color = "white") +
  annotate("segment", x = 97, xend = 113, y = 114, yend = 114, color = "white", arrow=arrow1) +
  annotate("text", x = 124, y = 110, label = "chorus", color = "white") +
  annotate("segment", x = 114, xend = 134, y = 114, yend = 114, color = "white", arrow=arrow1) +
  annotate("text", x = 144, y = 130, label = "outro", color = "white") +
  annotate("segment", x = 134, xend = 153, y = 134, yend = 134, color = "white", arrow=arrow1) +
  
  facet_wrap(~type) +
  scale_fill_viridis_c(end = .9, guide = "none", option = "inferno") +
  labs(x = NULL, y = NULL,
       title = "Self-similarity matrices for chroma and timbre",
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

Because this song produced remarkably nice self-similarity matrices, I decided to analyze it once more, but now focusing on homogeneity rather than the specific chroma and timbre features.

Both matrices clearly show (parts of) the song's structure (see below). The chroma matrix clearly shows the instrumental intro (first strip), the vocal intro, verse and outro (light strips), and the choruses with bridge (dark squares). It makes sense that both choruses are similar in pitch. Interestingly, the bridge resembles them. I could not figure out why, not by ear at least. Also interesting to see is that the second post-chorus is not similar to the first post-chorus. When you listen to the song, however, it *does* make a lot of sense; in the outro, the guitar stops playing.

The timbre matrix also clearly shows the outro, for the same reason actually. Timbre is partly determined by instrumentation, so it makes sense that the outro (without guitar) resembles no other part of the song (with guitar). Also notable is the dark square at the bottom-left corner of the timbre matrix. This represents the percussion coming in. In general, all squares in the timbre matrix can be ascribed to the homogeneity of the percussion. A new square indicates a change or short pause in the percussion -- even the slight changes just before 60 and 120 seconds represent a short percussion break of about a bar.

Also interesting, the vocal intro and the verse do not seem similar in pitch, yet they have the same repetitions (riffs probably). They are, overall, more similar in timbre. The bridge and choruses seem less similar in timbre than in pitch.

#### Song structure
Time (s) | Section             | Instrumentation
-------- | ------------------- | ----------
0-9      | intro               | guitar
10-19    | intro               | + percussion
19-38    | intro               | + voice
38-57    | chorus              |
57-76    | post-chorus         |
76-96    | verse               |
96-114   | bridge              |
114-134  | chorus              |
134-155  | outro / post-chorus | - guitar



<!-- ### <font size="3"> Achordingly, repetition is key </font> {data-commentary-width=500} -->

```{r chord and key templates, eval=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r chordogram setup, eval=FALSE}
cash <-
  get_tidy_audio_analysis("0URAjyKMW6cGfW6oFMTh6k") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

loop_niet_weg <-
  get_tidy_audio_analysis("7fmExiQZjHLyDv5SC1EhDg") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r chordogram, eval=FALSE}
cash %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",    # Try different distance metrics
    norm = "manhattan"       # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,120,15)) +
  scale_fill_viridis_c(guide = "none", option = "inferno") +
  theme_mine +
  theme(rect = element_blank(), line = element_blank()) +
  labs(x = "Time (s)", y = NULL, title = "Cash - Sarita Lorena")

loop_niet_weg %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",    # Try different distance metrics
    norm = "manhattan"       # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,200,15)) +
  scale_fill_viridis_c(guide = "none", option = "inferno") +
  theme_mine +
  theme(rect = element_blank(), line = element_blank()) +
  labs(x = "Time (s)", y = NULL, title = "Loop niet weg - Kris Kross Amsterdam")
```

<!-- *** -->
<!-- Both songs have a very tropical vibe. It's interesting to see that, assuming the chordogram is correct, both songs seem to use the same few chords throughout the whole song. Whereas "Cash" seems to hold the same chord for a few bars, "Loop niet weg" alternates between chords and then repeats that pattern. -->



### <font size="3"> The final chapter: ~~vaccination~~ classification </font> {data-commentary-width=450}
<!-- The final judgment -->

```{r classifier setup}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}

personal_features <-
  bind_rows(my2019, my2020, my2021) %>%
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

``` {r classifier recipe}
personal_recipe_all <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = personal_features,
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.

# personal_recipe_top <-
#   recipe(
#     playlist ~
#       energy + tempo + duration + speechiness + 
#       c01 + c02,
#     data = personal_features,
#   ) %>%
#   step_center(all_predictors()) %>%
#   step_scale(all_predictors())      # Converts to z-scores.

personal_cv <- personal_features %>% vfold_cv(5)
```

```{r k-Nearest Neighbor}
knn_model <-
  nearest_neighbor(neighbors = 2) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
personal_knn <- 
  workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )
personal_knn %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for all features with a k-nearest neighbor classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())
```

***
```{r knn precision}
knitr::kable(personal_knn %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")
```

On the left, you see a confusion matrix of a $k$-nearest neighbor classifier trying to classify my three personal playlists. As you can see, it performs rather okay on tracks from 2019 and 2021, yet very bad on tracks from 2020 (also see precision and recall in the table above). This could mean that my taste in music has shifted over the course of these three years and tracks from 2020 fall right in the middle. As a result, the classifier can only distinguish two classes and does not know what to do with 2020 tracks. This 'shift' from 2019 and 2021 has not been as clear in previous visualizations, where usually only 2021 showed a small difference from the other two.

The $k$-nearest neighbor classifier uses $k=1$. I have tried several values of $k$, but none produced significantly better results. Also, the random forest classifier performed significantly worse than this classifier. It could not at all predict the classes of 2019 and 2020 -- the prediction for both was about 33 tracks in each class. It did, however, perform better on the 2021 class. Maybe the random forest classifier was more heavily influenced by my 2021 playlist containing 110 tracks, as opposed to the 100 tracks in my 2019 and 2020 playlists. This makes sense when comparing it to the $k$-nearest neighbor classifier, because that one only considers the $k$-nearest neighbors and does not take 'the whole' into account.


<!-- #### Random forest -->
```{r random forest, eval=FALSE}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")

personal_forest <- 
  workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )
personal_forest_top <- 
  workflow() %>% 
  add_recipe(personal_recipe_top) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# personal_forest %>% get_conf_mat() %>% autoplot(type = "mosaic")
personal_forest %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for all features \nwith a random forest classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())
knitr::kable(personal_forest %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")

personal_forest_top %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for the top features \nwith a random forest classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())
knitr::kable(personal_forest_top %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")
```

<!-- The random forest classifiers perform much better. However, they are still not satisfactory and their results might even be considered insignificant. The second random forest classifier does seem to perform *somewhat* better than the first. The second only considers the following features: tempo, A, and all timbre features except c01 and c04. The plot below shows that these selected features indeed are more important than others. -->

```{r feature importance, eval=FALSE}
workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(forest_model) %>% 
  fit(personal_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value, fill = value)) + 
  scale_fill_viridis_c(begin = 0.2, end = 0.9, direction = -1, guide = "none", option = "inferno") +
  geom_col() + 
  coord_flip() +
  scale_y_continuous(expand = expansion(0.015)) +
  theme_mine +
  labs(subtitle = "Importance of features for a random forest classifier", x = NULL, y = NULL) +
  theme(panel.grid.minor.x = element_blank(),
        panel.border = element_blank(),
        axis.ticks = element_blank())
```



Epilogue
==================

### <font size="3"> 1. In terms of genre, how can my taste in music best be described? </font>
In most visualizations we saw a clear similarity between my personal playlists and the genres pop and R&B. My 2021 playlist usually shifted a little more towards R&B.

### <font size="3"> 2. How has my taste in music evolved during the COVID-19 pandemic? </font>
As the results have shown, I have started listening to more R&B songs in 2021. Also 2021 tracks were more often in minor than tracks from 2019 and 2020. Also according to the $k$-nearest neighbor classifier, my music taste has indeed shifted since 2019. It shows that tracks from 2020 were hard to classify, probably because 2019 and 2021 were so clearly different from each other.

### <font size="3"> Outlook </font>
This corpus research has actually been for personal interest only. It might be nice to analyze music trends over the COVID-19 pandemic in general, but my corpus would in no way suffice for that analysis.

Recently, I have started listening to more Dutch music. I wonder whether, in the future, I can research such 'language trends' as well. I have also started wondering whether I have seasonal preferences. I could imagine the following seasonal pattern:

Time of the year | Winter  | Summer
---------------- | ------- | -------------
Energy-valence   | relaxed | upbeat
Genre            | R&B-ish | Latin and pop
Mode             | minor   | major




```{r track comparison, eval=FALSE}
# Mr Eazi:      7IgVM0GW96uXhM5XUeYgH9    ééntonig
# Hey Mama:     285HeuLxsngjFn4GGegGNm    duidelijke verse-chorus structuur
# Sweetie Odo:  2UAl2nzSixQviGw0XJvJgY    mooie self-similarity matrices
# Cash:         0URAjyKMW6cGfW6oFMTh6k    
```

<!-- Data visualization: -->
<!-- - https://rkabacoff.github.io/datavis/Time.html#dummbbell-charts -->
<!-- - spider chart: https://www.r-graph-gallery.com/spider-or-radar-chart.html -->
<!-- - circular barplot: https://www.r-graph-gallery.com/circular-barplot.html -->
<!-- http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization -->