---
title: "Measuring Covid Measures"
author: "Tisja Smits"
date: "2021"
output: 
    flexdashboard::flex_dashboard:
      orientation: rows
      storyboard: true
      theme: journal # default / cosmo / bootstrap / cerulean / journal! / flatly! / readable / spacelab / united / lumen / paper / sandstone / simplex! / yeti!
---

<style type="text/css">
  body{
  font-family: "Rubik", Light;
  color: black;
  }
</style>


```{r package and theme setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(spotifyr)
library(compmus)

library(flexdashboard)
library(plotly)
library(gridExtra)

library(tidymodels)
library(ggdendro)
library(heatmaply)

theme_mine <-
  theme_minimal() +
  theme(
    text = element_text(family = "Rubik"),
    legend.title = element_blank(),
    strip.text = element_text(color = "black"),
    strip.background = element_rect(fill = "gray90", color = NA),
    panel.border = element_rect(fill = NA, color = "gray80"),
    axis.ticks = element_line(color = "gray80")
    )
```

```{r toptracks setup, include=FALSE}
my2019 <- get_playlist_audio_features("", "37i9dQZF1Etf5utVpuKPi7")  %>% 
  mutate(playlist = "2019", category = "personal")
my2020 <- get_playlist_audio_features("", "37i9dQZF1ELZX0wn2u2RJw") %>% 
  mutate(playlist = "2020", category = "personal")
my2021 <- bind_rows(
  get_playlist_audio_features("", "6US6AXRPEDXScdalyqL3z4"),
  get_playlist_audio_features("", "3o3ct2BSsEfiO2jV7qycsl")
  ) %>% mutate(playlist = "2021", category = "personal")

pop <- get_playlist_audio_features("", "37i9dQZF1DX6gRTxU4AfAv") %>% 
  mutate(playlist = "Pop", category = "genres")
dance <- get_playlist_audio_features("", "37i9dQZF1DX0W5G2DBOR2F") %>% 
  mutate(playlist = "Dance", category = "genres")
hiphop <- get_playlist_audio_features("", "37i9dQZF1DX6rJpshxuzGT")[1:50,] %>% 
  mutate(playlist = "Hip-Hop/R&B", category = "genres")
indie <- get_playlist_audio_features("", "37i9dQZF1DWYeyJxik6dE1") %>% 
  mutate(playlist = "Indie/Rock", category = "genres")

corpus <-
  bind_rows(my2019, my2020, my2021, pop, dance, hiphop, indie)

corpus_stats <- corpus %>% 
  group_by(playlist) %>%
  summarise(
    category = "stat",
    valence_sd = sd(valence),
    valence = mean(valence),
    energy_sd = sd(energy),
    energy = mean(energy),
    tempo_sd = sd(tempo),
    tempo = mean(tempo),
    danceability_sd = sd(danceability),
    danceability = mean(danceability),
    loudness_sd = sd(loudness),
    loudness = mean(loudness),
    track.name = NA,     # or "average"
    time_signature = median(time_signature),
    key = median(key),
    mode_sd = sd(mode),
    mode = mean(mode),
    mode_name = NA
    )
```

Prologue
==================

### Just an average girl?

My initial corpus consisted of my Top Tracks of 2019 and 2020 and the Top Tracks NL of 2019 and 2020. I wanted to analyze how 'average' my taste in music was, and how it changed during the COVID-19 pandemic. Due to the **social distancing measures** I did not listen to music in any social setting, such as hanging out with friends, clubbing, or even working out at the gym.

After seven weeks of homework assignments, disappointing results and hence disappointing data visualizations, I decided to change my corpus. The Top Tracks NL playlists were too 'general' to really capture any meaning or essence of 'the average Dutch taste in music'.

### A clean slate

My new corpus consists of 510 tracks from 7 playlists in total. I still use my Top Tracks of 2019 and 2020, but I have added my own 2021 playlist. This way, 2019 represents the pre-pandemic situation and 2021 represent the one-year mark. The other four playlists are playlists of the NL top tracks of 2020, but one for each of the following genres: pop, dance, hip-hop/R&B and indie/rock. These genre playlists are shown below.

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX6gRTxU4AfAv" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX0W5G2DBOR2F" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX6rJpshxuzGT" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DWYeyJxik6dE1" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

With this clean slate, I want to analyze the following:
**1. In terms of genre, how can my taste in music best be described?**
**2. How has my taste in music evolved during the COVID-19 pandemic?**

It is important to note that the playlists do not contain the same amount of tracks. The four genre playlists each contain 50 tracks. My 2019 and 2020 playlists contain 100 tracks and my 2021 playlist contains 110 tracks. I deciced not to take out the extra 10, because there was no satisfactory objective way of doing so.

It is also important to note that my 2021 playlist is the *only* playlist I have compiled myself, the others were compiled by Spotify. It might be the case that Spotify biases the playlists by including certain --possibly sponsored-- songs. Although I do not consider this plausible, it is important to keep in mind.

More plausible is the possibility of my personal Top Tracks playlists being biased, for different reasons however. First, I do not have a premium Spotify account, which means I get a limited amount of skips per hour and most playlists can only be played on shuffle. It might be that a song ended up a Top Track because it was in a playlist I listened to a lot, not because I liked that song so much. This limitation, however, only applies when listening to Spotify on my phone. The desktop version of Spotify *does* allow for infinite skips and the freedom to choose songs manually, put songs in the waiting list, and play a playlist on shuffle or in order. 

A great example of a dubious song is **"Stuck with U" by Ariana Grande and Justin Bieber**. It is one of my Top Tracks of 2020. It used to be in a lot of different playlists I listened to at the time. And yes, I liked that song, but nevertheless, I am fairly sure there were other songs I liked more in 2020. I definitely consider this song atypical for my taste in music in 2020.

<iframe src="https://open.spotify.com/embed/track/4HBZA5flZLE435QTztThqH" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

Contrarily, a song I consider very typical for my taste is **"Drive and Disconnect" by Nao**. I remember listening to this song on repeat when I discovered it early 2019, but also for a longer time after that. And even a few months later I rediscovered this song, and fell in love all over again. Even now, it is still one of my favorite songs.

<iframe src="https://open.spotify.com/embed/track/6pEAd0UjznaKABT7WLLvmC" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>



A good first impression {.storyboard}
==================

### <font size="4"> An emotional analysis of the lockdown: (no) time to relax </font>

```{r mood plot, fig.align="center"}
ggplotly(ggplot(
    corpus,
    aes(x = valence,
        y = energy,
        color = valence + energy,
        label = track.name)) +
  geom_point(alpha = 0.5) +
  scale_color_viridis(guide = "none", option = "inferno") +

  geom_segment(
    data = corpus_stats, 
    aes(x = valence, 
        y = energy-energy_sd, 
        xend = valence, 
        yend = energy+energy_sd)) +
  geom_segment(
    data = corpus_stats, 
    aes(x = valence-valence_sd, 
        y = energy, 
        xend = valence+valence_sd, 
        yend = energy)) +
  geom_point(
    data = corpus_stats,
    size = 2.5) +

  scale_x_continuous(breaks=seq(0,1,0.25)) +
  scale_y_continuous(breaks=seq(0,1,0.25)) +
  facet_wrap(~playlist) +
  labs(x = "Valence",
       y = "Energy",
       title = "Scatter plot of energy versus valence",
       subtitle = "with mean and SD per playlist") +
  theme_mine,
  width = 800
)
```

***
Here comes the analysis


### **knaldrag** [knal-drang] *noun* -- The intense desire to go out, to party, to dance.

```{r dance plot, fig.align="center"}
ggplotly(ggplot(
    corpus,
    aes(x = tempo,
        y = danceability,
        color = tempo * danceability,
        label = track.name)) +
  geom_point(alpha = 0.5) +
  scale_color_viridis(guide = "none", option = "inferno") +

  geom_segment(
    data = corpus_stats, 
    aes(x = tempo, 
        y = danceability-danceability_sd, 
        xend = tempo, 
        yend = danceability+danceability_sd)) +
  geom_segment(
    data = corpus_stats, 
    aes(x = tempo-tempo_sd, 
        y = danceability, 
        xend = tempo+tempo_sd, 
        yend = danceability)) +
  geom_point(
    data = corpus_stats,
    size = 2.5) +

  scale_x_continuous(breaks=seq(20,220,40)) +
  # scale_y_continuous(breaks=seq(0,1,0.25)) +
  facet_wrap(~playlist) +
  labs(x = "Tempo (bpm)",
       y = "Danceability",
       title = "Scatter plot of danceability versus tempo",
       subtitle = "with mean and SD per playlist") +
  theme_mine,
  width = 800
)
```

***
My playlists all seem to have a cluster around 100 bpm. The same holds for the genres hip-hop/R&B and pop. (Notice that all of their means are slightly higher, since they spread out more to the right.) Indie/rock is clustered more around 120 bpm, and dance even more so.

The average danceabilities of my playlists lie between 0.6 and 0.9. The means, of about 0.7 confirm this. Dance tracks from about 0.5 to 0.9, also with a mean of 0.7. Not surprisingly, pop and indie/rock tracks have a somewhat lower danceability. Hip-hop/R&B tracks, however, have a slightly higher danceability.


### It's in the minor details of this major pandemic

```{r mode barplot, fig.align="center"}
ggplotly(ggplot(
  corpus,
  aes(x = playlist,
      fill = mode_name)) +
  geom_bar(position = "fill", alpha = 0.75) +

  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL, y = NULL, title = "Distribution of modes across playlists") +
  theme_mine +
  theme(panel.grid.major.x = element_blank()),
  width = 800
)
```

***
My Top Tracks playlists clearly count more minor modes (64%) than the NL Top Tracks playlists (49%). Also, there is a slight increase in minor tracks in 2020 as opposed to 2019.

It is immediately apparent that the indie/rock and pop playlists contain relatively more major than minor tracks, as opposed to the other playlists. Also, my 2021 tracks are more likely to be in minor mode than my Top Tracks of 2019 or 2020. As in the energy-valence visualization, this might indicate that my taste in music has slightly shifted towards R&B.



Getting on track {.storyboard}
==================

```{r gram setup}
sweetie <-
  get_tidy_audio_analysis("2UAl2nzSixQviGw0XJvJgY") %>%  # Change URI.
  compmus_align(bars, segments) %>%                      # Change `bars`
  select(bars) %>%                                       #   in all three
  unnest(bars) %>%                                       #   of these lines.
  mutate(pitches = map(
    segments, compmus_summarise, pitches,
    method = "mean", norm = "euclidean"              # Change summary & norm.
      )) %>%
  mutate(timbre = map(
    segments, compmus_summarise, timbre,
    method = "rms", norm = "euclidean"               # Change summary & norm.
    ))
sweetie_sec <-
  get_tidy_audio_analysis("2UAl2nzSixQviGw0XJvJgY") %>%  # Change URI.
  compmus_align(sections, segments) %>%                      # Change `bars`
  select(sections) %>%                                       #   in all three
  unnest(sections) %>%                                       #   of these lines.
  mutate(pitches = map(
    segments, compmus_summarise, pitches,
    method = "mean", norm = "euclidean"              # Change summary & norm.
    )) %>%
  mutate(timbre = map(
    segments, compmus_summarise, timbre,
    method = "rms", norm = "euclidean"               # Change summary & norm.
    ))
```

### Repetitive chord progressions and vocal 'blocks' {data-commentary-width=300}

```{r chromagrams bars and sections}
bind_rows(
  sweetie %>% 
    compmus_gather_chroma() %>% mutate(type = "Bars"),
  sweetie_sec %>% 
    compmus_gather_chroma() %>% mutate(type = "Sections")
  ) %>%
  mutate() %>% ggplot(
    aes(x = start + duration / 2,
        width = duration,
        y = pitch_class,
        fill = value)) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_fill_viridis_c("Magnitude", option = "inferno") +
  facet_wrap(~type) +
  labs(x = "Time (s)", y = NULL, 
       title = "Chromagrams", 
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(legend.title = element_text(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

This song was a typical Top Track of mine in 2020 (see song info). In the bars chromagram, you can clearly see the repetitive chord progression throughout the song -- the skips from C to A to G. The sections chromagram clearly shows bright 'blocks' at D and C. The D-blocks represent the chorus vocals and the C-block represents the vocals in the bridge. The first few blocks at G, F and D represent the intro.

I think the overall look of these chromagrams are very representative of the tracks I generally listen to. Speaking from a music theoretic point of view, most songs have a standard verse-chorus structure (as shown by the the sections chromagram) and simple melodies and harmonies (as shown by the bars chromagram).

##### Song info
Feature        | Average in 2020                         | "Sweetie Odo" 
---------------|-----------------------------------------|--------------
Time Signature | `r median(my2020$time_signature)`       | 4
BPM            | `r round(mean(my2020$tempo), 2)`        | 100
Energy         | `r round(mean(my2020$energy), 2)`       | 0.49
Valence        | `r round(mean(my2020$valence), 2)`      | 0.53
Danceability   | `r round(mean(my2020$danceability), 2)` | 0.84



### Different sounds in different sections {data-commentary-width=300}
```{r cepstrograms bars and sections}
bind_rows(
  sweetie %>% 
    compmus_gather_timbre() %>% mutate(type = "Bars"),
  sweetie_sec %>% 
    compmus_gather_timbre() %>% mutate(type = "Sections")
) %>%
  mutate() %>% ggplot(
    aes(x = start + duration / 2,
        width = duration,
        y = basis,
        fill = value)) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_fill_viridis_c("Magnitude", option = "inferno") +
  facet_wrap(~type) +
  labs(x = "Time (s)", y = NULL,
       title = "Cepstrograms",
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(legend.title = element_text(),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

This song was a typical Top Track of mine in 2020 (see song info). Both cepstrograms clearly show the intro and outro in the third timbre component. The verses are also brighter in c03. The chorus sections, however, light up in c05. I wonder what this component represents. The second timbre component most clearly shows the bridge and the choruses somewhat.

What is most representative about this song, and clearly visualized in these cepstrograms, is that most songs I listen to have an intro and outro. Also, I believe I do not listen to many songs where the loudness -- the first timbre component -- changes a lot.

##### Song info
Feature        | Average in 2020                         | "Sweetie Odo" 
---------------|-----------------------------------------|--------------
Time Signature | `r median(my2020$time_signature)`       | 4
BPM            | `r round(mean(my2020$tempo), 2)`        | 100
Energy         | `r round(mean(my2020$energy), 2)`       | 0.49
Valence        | `r round(mean(my2020$valence), 2)`      | 0.53
Danceability   | `r round(mean(my2020$danceability), 2)` | 0.84



### Self-similarity matrices
```{r self-similarity matrices}
bind_rows(
  sweetie %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  sweetie %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  scale_x_continuous(breaks=seq(0,155,30)) +
  scale_y_continuous(breaks=seq(0,155,30)) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none", option = "inferno") +
  labs(x = NULL, y = NULL,
       title = "Self-similarity matrices for chroma and timbre",
       subtitle = "'Sweetie Odo' by Juls featuring Sway Clarke") +
  theme_mine +
  theme(panel.border = element_blank())
```

***
<iframe src="https://open.spotify.com/embed/track/2UAl2nzSixQviGw0XJvJgY" width="300" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

The song has the following structure:

Time (s) | Section     | Instrumentation
-------- | ----------- | ----------
0-9      | intro       | guitar
10-19    | intro       | + percussion
19-38    | intro       | + voice
38-57    | chorus      |
57-76    | post-chorus |
76-96    | verse       |
96-114   | bridge      |
114-134  | chorus      |
134-155  | post-chorus | - guitar

Both matrices clearly show (parts of) the song's structure. The chroma matrix clearly shows the instrumental intro (first strip), the vocal intro, outro and verse (light strips), and the choruses with bridge (dark squares). It makes sense that both choruses are similar in pitch. Interestingly, the bridge resembles them. 

Also interesting to see is that the second post-chorus is not similar to the first post-chorus. When you listen to the song, however, it *does* make a lot of sense; in the outro, the guitar stops playing.

The timbre matrix also clearly shows the outro, for the same reason actually. Timbre is partly determined by instrumentation, so it makes sense that the outro (without guitar) resembles no other part of the song (with guitar).

Notable is the dark square at the bottom-left corner of the timbre matrix. This represents the percussion coming in. In general, all squares in the timbre matrix can be ascribed to the homogeneity of the percussion. A new square indicates a change or short pause in the percussion -- even the slight changes just before 60 and 120 seconds represent a short percussion break of about a bar.

Also interesting, the vocal intro and the verse do not seem to be similar in pitch, but they do in timbre. The bridge and choruses, however, seem less similar in timbre than in pitch.



### Achordingly, repetition is key

```{r chord and key templates}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r chordogram setup}
cash <-
  get_tidy_audio_analysis("0URAjyKMW6cGfW6oFMTh6k") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

loop_niet_weg <-
  get_tidy_audio_analysis("7fmExiQZjHLyDv5SC1EhDg") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r chordogram}
cash %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",    # Try different distance metrics
    norm = "manhattan"       # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,120,15)) +
  scale_fill_viridis_c(guide = "none", option = "inferno") +
  theme_mine +
  theme(rect = element_blank(), line = element_blank()) +
  labs(x = "Time (s)", y = NULL, title = "Cash - Sarita Lorena")

loop_niet_weg %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",    # Try different distance metrics
    norm = "manhattan"       # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=seq(0,200,15)) +
  scale_fill_viridis_c(guide = "none", option = "inferno") +
  theme_mine +
  theme(rect = element_blank(), line = element_blank()) +
  labs(x = "Time (s)", y = NULL, title = "Loop niet weg - Kris Kross Amsterdam")
```

***
Both songs have a very tropical vibe. It's interesting to see that, assuming the chordogram is correct, both songs seem to use the same few chords throughout the whole song. Whereas "Cash" seems to hold the same chord for a few bars, "Loop niet weg" alternates between chords and then repeats that pattern.



### The final chapter: ~~vaccination~~ classification
<!-- The final judgment -->

```{r classifier setup, eval=FALSE}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}

personal_features <-
  bind_rows(my2019, my2020, my2021) %>%
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

``` {r classifier recipe, eval=FALSE}
personal_recipe_all <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = personal_features,
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.

personal_recipe_top <-
  recipe(
    playlist ~
      energy + tempo + duration + speechiness + 
      c01 + c02,
    data = personal_features,
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.

personal_cv <- personal_features %>% vfold_cv(5)
```

#### k-nearest neighbor
```{r k-Nearest Neighbor, eval=FALSE}
knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
personal_knn <- 
  workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )
personal_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
personal_knn %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for all features \nwith a k-nearest neighbor classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())

knitr::kable(personal_knn %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")
```

As can be seen in the confusion matrix above, the k-nearest neighbor classifier performs badly. However disappointing, this result is not surprising. Just as we have seen no big differences between the four playlists overall, it makes sense that nearest neighbors might not be from the 'correct' playlist.

#### Random forest
```{r random forest, eval=FALSE}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")

personal_forest <- 
  workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )
personal_forest_top <- 
  workflow() %>% 
  add_recipe(personal_recipe_top) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    personal_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# personal_forest %>% get_conf_mat() %>% autoplot(type = "mosaic")
personal_forest %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for all features \nwith a random forest classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())
knitr::kable(personal_forest %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")

personal_forest_top %>% get_conf_mat() %>% 
  autoplot(type = "heatmap") + 
  labs(subtitle = "Confusion matrix for the top features \nwith a random forest classifier") +
  scale_fill_viridis_c(begin = 0.3, direction = -1, guide = "none", option = "inferno") +
  theme_mine +
  theme(panel.grid = element_blank(), 
        panel.border = element_blank(),
        axis.ticks = element_blank())
knitr::kable(personal_forest_top %>% get_pr(), 
             format = "html", 
             table.attr = "style='width:30%;'")
```

The random forest classifiers perform much better. However, they are still not satisfactory and their results might even be considered insignificant. The second random forest classifier does seem to perform *somewhat* better than the first. The second only considers the following features: tempo, A, and all timbre features except c01 and c04. The plot below shows that these selected features indeed are more important than others.

```{r feature importance, eval=FALSE}
workflow() %>% 
  add_recipe(personal_recipe_all) %>% 
  add_model(forest_model) %>% 
  fit(personal_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value, fill = value)) + 
  scale_fill_viridis_c(begin = 0.2, end = 0.9, direction = -1, guide = "none", option = "inferno") +
  geom_col() + 
  coord_flip() +
  scale_y_continuous(expand = expansion(0.015)) +
  theme_mine +
  labs(subtitle = "Importance of features for a random forest classifier", x = NULL, y = NULL) +
  theme(panel.grid.minor.x = element_blank(),
        panel.border = element_blank(),
        axis.ticks = element_blank())
```




Epilogue
==================

### 1. In terms of genre, how can my taste in music best be described?

### 2. How has my taste in music evolved during the COVID-19 pandemic?

### Outlook
I have started listening to more Dutch music.
Whether I have seasonal preferences. I can imagine the following seasonal pattern:

Time of the year | Winter  | Summer
---------------- | ------- | -------------
Energy-valence   | relaxed | upbeat
Genre            | R&B-ish | Latin and pop
Mode             | minor   | major




```{r track comparison, eval=FALSE}
# Mr Eazi:      7IgVM0GW96uXhM5XUeYgH9    ééntonig
# Hey Mama:     285HeuLxsngjFn4GGegGNm    duidelijke verse-chorus structuur
# Sweetie Odo:  2UAl2nzSixQviGw0XJvJgY    mooie self-similarity matrices
# Cash:         0URAjyKMW6cGfW6oFMTh6k    
```

<!-- Data visualization: -->
<!-- - https://rkabacoff.github.io/datavis/Time.html#dummbbell-charts -->
<!-- - spider chart: https://www.r-graph-gallery.com/spider-or-radar-chart.html -->
<!-- - circular barplot: https://www.r-graph-gallery.com/circular-barplot.html -->
<!-- http://www.sthda.com/english/wiki/ggplot2-scatter-plots-quick-start-guide-r-software-and-data-visualization -->